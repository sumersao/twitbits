{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, BertModel, LEDForConditionalGeneration\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from datasets import load_metric\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our augmented dataset json file\n",
    "augmented_dataset = None\n",
    "with open('augmented_test.json', 'r') as f:\n",
    "    augmented_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e028b6d412324768838385d5098a98b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4fcd2cbc3e4bf4ba584d17de9a8f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91e2ab3e54749ff99e6f54e67cabc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7791e54d86d949fd963df3379f1c61b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caca439430484cb6baa29f30fb5363da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# load our model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_documents(documents):\n",
    "    doc_embeddings = []\n",
    "    for doc in documents:\n",
    "        inputs = tokenizer.encode_plus(doc, max_length=512, pad_to_max_length=True, return_tensors=\"pt\")\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        # we're going to average across the tokens to get the sentence embedding\n",
    "        doc_embedding = torch.mean(last_hidden_states, dim=1)\n",
    "        doc_embeddings.append(doc_embedding)\n",
    "    \n",
    "    return doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_documents_kmeans(documents):\n",
    "    doc_embeddings = embed_documents(documents)\n",
    "    # turn our list of embeddings into a numpy matrix\n",
    "    doc_embeddings = torch.cat(doc_embeddings).detach().numpy()\n",
    "    # cluster them into 3 clusters\n",
    "    kmeans = KMeans(n_clusters=3, random_state=0).fit(doc_embeddings)\n",
    "    return kmeans.labels_\n",
    "\n",
    "def cluster_documents_hierarchical(documents):\n",
    "    doc_embeddings = embed_documents(documents)\n",
    "    # turn our list of embeddings into a numpy matrix\n",
    "    doc_embeddings = torch.cat(doc_embeddings).detach().numpy()\n",
    "    # cluster them into 3 clusters\n",
    "    hierarchical = AgglomerativeClustering(n_clusters=3).fit(doc_embeddings)\n",
    "    return hierarchical.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our model\n",
    "TOKENIZER = AutoTokenizer.from_pretrained('allenai/PRIMERA')\n",
    "MODEL = LEDForConditionalGeneration.from_pretrained('allenai/PRIMERA').to(device)\n",
    "\n",
    "PAD_TOKEN_ID = TOKENIZER.pad_token_id\n",
    "DOCSEP_TOKEN_ID = TOKENIZER.convert_tokens_to_ids(\"<doc-sep>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our indices to use\n",
    "sample_indices = pd.read_csv('cohere_sample_indices.csv').values.flatten()\n",
    "dataset_small = [augmented_dataset[i] for i in sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(documents):\n",
    "    input_ids_all=[]\n",
    "    #### concat with global attention on doc-sep\n",
    "    input_ids = []\n",
    "    for doc in documents:\n",
    "        input_ids.extend(\n",
    "            TOKENIZER.encode(\n",
    "                doc,\n",
    "                truncation=True,\n",
    "                max_length=4096 // len(documents),\n",
    "            )[1:-1]\n",
    "        )\n",
    "        input_ids.append(DOCSEP_TOKEN_ID)\n",
    "    input_ids = (\n",
    "        [TOKENIZER.bos_token_id]\n",
    "        + input_ids\n",
    "        + [TOKENIZER.eos_token_id]\n",
    "    )\n",
    "    input_ids_all.append(torch.tensor(input_ids).to(device))\n",
    "    input_ids_final = torch.nn.utils.rnn.pad_sequence(\n",
    "        input_ids_all, batch_first=True, padding_value=PAD_TOKEN_ID\n",
    "    ).to(device)\n",
    "\n",
    "    return input_ids_final\n",
    "\n",
    "\"\"\"\n",
    "For each cluster, use each document in input. Output 512/3 tokens for each cluster. Append them. \n",
    "\"\"\"\n",
    "def process_clusters_concat(data, clusters):\n",
    "    documents = data['documents']\n",
    "    # create a list of lists, where each list is a cluster\n",
    "    cluster_docs = [[] for _ in range(3)]\n",
    "    for i, doc in enumerate(documents):\n",
    "        cluster_docs[clusters[i]].append(doc)\n",
    "    cluster_summaries = []\n",
    "    \n",
    "    # now run the summarization on each cluster\n",
    "    for cluster in cluster_docs:\n",
    "        input_ids = process_document(cluster)\n",
    "        # get the input ids and attention masks together\n",
    "        global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
    "        # put global attention on <s> token\n",
    "\n",
    "        global_attention_mask[:, 0] = 1\n",
    "        global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
    "\n",
    "        generated_ids = MODEL.generate(\n",
    "            input_ids=input_ids,\n",
    "            global_attention_mask=global_attention_mask,\n",
    "            use_cache=True,\n",
    "            max_length=512//3,\n",
    "            num_beams=5,\n",
    "        )\n",
    "\n",
    "        generated_str = TOKENIZER.batch_decode(\n",
    "                generated_ids.tolist(), skip_special_tokens=True\n",
    "            )\n",
    "        cluster_summaries.append(generated_str)\n",
    "    \n",
    "    result={}\n",
    "    # concatenate the summaries\n",
    "    result['generated_summaries'] = [' '.join(cluster) for cluster in cluster_summaries]\n",
    "    result['gt_summaries']= data['summary']\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Take 1 random document from each cluster and just use that to summarize (idea — get more context on \n",
    "each document). Output max length still 512 tokens. \n",
    "\"\"\"\n",
    "def process_clusters_one_doc(data, clusters):\n",
    "    documents = data['documents']\n",
    "    # create a list of lists, where each list is a cluster\n",
    "    cluster_docs = [[] for _ in range(3)]\n",
    "    for i, doc in enumerate(documents):\n",
    "        cluster_docs[clusters[i]].append(doc)\n",
    "\n",
    "    new_docs = [cluster[0] for cluster in cluster_docs]\n",
    "    input_ids = process_document(new_docs)\n",
    "    \n",
    "    # get the input ids and attention masks together\n",
    "    global_attention_mask = torch.zeros_like(input_ids).to(input_ids.device)\n",
    "    # put global attention on <s> token\n",
    "\n",
    "    global_attention_mask[:, 0] = 1\n",
    "    global_attention_mask[input_ids == DOCSEP_TOKEN_ID] = 1\n",
    "\n",
    "    generated_ids = MODEL.generate(\n",
    "        input_ids=input_ids,\n",
    "        global_attention_mask=global_attention_mask,\n",
    "        use_cache=True,\n",
    "        max_length=512,\n",
    "        num_beams=5,\n",
    "    )\n",
    "\n",
    "    generated_str = TOKENIZER.batch_decode(\n",
    "            generated_ids.tolist(), skip_special_tokens=True\n",
    "        )\n",
    "    \n",
    "    result={}\n",
    "    result['generated_summaries'] = generated_str\n",
    "    result['gt_summaries']= data['summary']\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our pipeline using kmeans clustering\n",
    "\n",
    "result_small_one_doc = []\n",
    "result_small_concat = []\n",
    "\n",
    "for i in tqdm(range(0, len(dataset_small))):\n",
    "    data = dataset_small[i]\n",
    "    k_clusters = cluster_documents_kmeans(data['documents'])\n",
    "    \n",
    "\n",
    "    result_small_one_doc.append(process_clusters_one_doc(data, k_clusters))\n",
    "    result_small_concat.append(process_clusters_concat(data, k_clusters))\n",
    "\n",
    "    # let's save the result every 50 points\n",
    "    if i % 50 == 0:\n",
    "        with open(f\"results/kmeans_bert_one_doc{i}.json\", \"w\") as f:\n",
    "            json.dump(result_small_one_doc, f)\n",
    "        \n",
    "        with open(f\"results/kmeans_bert_concat{i}.json\", \"w\") as f:\n",
    "            json.dump(result_small_concat, f)\n",
    "        \n",
    "\n",
    "with open(f\"results/kmeans_bert_one_doc_complete.json\", \"w\") as f:\n",
    "    json.dump(result_small_one_doc, f)\n",
    "\n",
    "with open(f\"results/kmeans_bert_concat_complete.json\", \"w\") as f:\n",
    "    json.dump(result_small_concat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries_one_doc_kmeans = [result['generated_summaries'] for result in result_small_one_doc]\n",
    "generated_summaries_concat_kmeans = [result['generated_summaries'] for result in result_small_concat]\n",
    "gt_summaries = [result['gt_summaries'] for result in result_small_one_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run our pipeline using hierarchical clustering\n",
    "result_small_one_doc = []\n",
    "result_small_concat = []\n",
    "\n",
    "for i in tqdm(range(0, len(dataset_small))):\n",
    "    data = dataset_small[i]\n",
    "    k_clusters = cluster_documents_hierarchical(data['documents'])\n",
    "\n",
    "    result_small_one_doc.append(process_clusters_one_doc(data, k_clusters))\n",
    "    result_small_concat.append(process_clusters_concat(data, k_clusters))\n",
    "\n",
    "    # let's save the result every 50 points\n",
    "    if i % 50 == 0:\n",
    "        with open(f\"results/hierarchical_bert_one_doc{i}.json\", \"w\") as f:\n",
    "            json.dump(result_small_one_doc, f)\n",
    "        \n",
    "        with open(f\"results/hierarchical_bert_concat{i}.json\", \"w\") as f:\n",
    "            json.dump(result_small_concat, f)\n",
    "        \n",
    "\n",
    "with open(f\"results/hierarchical_bert_one_doc_complete.json\", \"w\") as f:\n",
    "    json.dump(result_small_one_doc, f)\n",
    "\n",
    "with open(f\"results/hierarchical_bert_concat_complete.json\", \"w\") as f:\n",
    "    json.dump(result_small_concat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summaries_one_doc_hier = [result['generated_summaries'] for result in result_small_one_doc]\n",
    "generated_summaries_concat_hier = [result['generated_summaries'] for result in result_small_concat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13775/4132584981.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.5438948266979868, recall=0.10124836586589471, fmeasure=0.15783020133269246)\n",
      "Score(precision=0.15513605011561674, recall=0.028008054507286547, fmeasure=0.043857190521232714)\n",
      "Score(precision=0.3027665405691981, recall=0.05084582111477903, fmeasure=0.08078598979052015)\n",
      "Score(precision=0.5274445057328687, recall=0.21637730464442273, fmeasure=0.300328049555533)\n",
      "Score(precision=0.14703946588296857, recall=0.06028979730250525, fmeasure=0.08362263712052559)\n",
      "Score(precision=0.222056527068549, recall=0.08893422004968742, fmeasure=0.12415033214650802)\n"
     ]
    }
   ],
   "source": [
    "score=rouge.compute(predictions=generated_summaries_one_doc_kmeans, references=gt_summaries)\n",
    "print(score['rouge1'].mid)\n",
    "print(score['rouge2'].mid)\n",
    "print(score['rougeL'].mid)\n",
    "\n",
    "score=rouge.compute(predictions=generated_summaries_concat_kmeans, references=gt_summaries)\n",
    "print(score['rouge1'].mid)\n",
    "print(score['rouge2'].mid)\n",
    "print(score['rougeL'].mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score(precision=0.541798597420081, recall=0.09436502257761334, fmeasure=0.15049149557628166)\n",
      "Score(precision=0.15667819254377463, recall=0.025847011319358484, fmeasure=0.04167678279955345)\n",
      "Score(precision=0.30809652436601975, recall=0.04859348410903109, fmeasure=0.07893123065437563)\n",
      "Score(precision=0.5297296739636896, recall=0.2165673869883918, fmeasure=0.30042539487876196)\n",
      "Score(precision=0.14814141121508817, recall=0.06052392144119931, fmeasure=0.08394333854341451)\n",
      "Score(precision=0.22926772696612138, recall=0.09131096584239795, fmeasure=0.1274268786298654)\n"
     ]
    }
   ],
   "source": [
    "score=rouge.compute(predictions=generated_summaries_one_doc_hier, references=gt_summaries)\n",
    "print(score['rouge1'].mid)\n",
    "print(score['rouge2'].mid)\n",
    "print(score['rougeL'].mid)\n",
    "\n",
    "score=rouge.compute(predictions=generated_summaries_concat_hier, references=gt_summaries)\n",
    "print(score['rouge1'].mid)\n",
    "print(score['rouge2'].mid)\n",
    "print(score['rougeL'].mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
