{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load dataset .json file. \n",
    "'''\n",
    "dataset_path = 'augmented_test.json'\n",
    "\n",
    "with open(dataset_path) as file:\n",
    "    dataset = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Choose random sample from dataset. Save the sample indices to 'cohere_sample_indices.csv'.  \n",
    "'''\n",
    "'''\n",
    "sample_size = 200 # for testing, change to ~200 for actual experiment\n",
    "\n",
    "sample_indices = random.sample(range(len(dataset)), sample_size)\n",
    "df_indices = pd.DataFrame(sample_indices, columns=['Indices'])\n",
    "df_indices.to_csv('cohere_sample_indices.csv', index=False) # save indices for later summarization comparison\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Read in sample indices from 'cohere_sample_indices.csv', get random sample from dataset.\n",
    "Combine documents within each datapoint to feed into cohere api. \n",
    "'''\n",
    "df_indices = pd.read_csv('cohere_sample_indices.csv')\n",
    "sample_indices = df_indices['Indices'].values.tolist()\n",
    "#sample_indices = sample_indices[0:5] # take out when running actual experiment\n",
    "\n",
    "sample_dataset_text = [dataset[i]['documents'] for i in sample_indices]\n",
    "\n",
    "input_size = 4096\n",
    "short_sample_dataset_text = []\n",
    "for datapoint in sample_dataset_text:\n",
    "    document_size = int(0.5 * input_size / len(datapoint)) # each doc's token length is 1/(# documents) input_size, assume each word is 2 tokens\n",
    "    first_words = [doc[:document_size] for doc in datapoint]\n",
    "    short_sample_dataset_text.append(first_words)\n",
    "\n",
    "#concat_sample_dataset = [' '.join(i) for i in sample_dataset_text] # for full documents\n",
    "concat_short_sample_dataset = [' '.join(i) for i in short_sample_dataset_text]\n",
    "\n",
    "#original_text = concat_sample_dataset # for full documents\n",
    "shortened_text = concat_short_sample_dataset\n",
    "\n",
    "#print(original_text[0])\n",
    "#print(shortened_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Use cohere api to generate summaries, and save to output file 'cohere_summaries.txt'.\n",
    "'''\n",
    "\n",
    "co = cohere.Client('PcE6kHvoamLYwNGqcGHcnkpF23LV4WkCO4CSH1mB')\n",
    "\n",
    "'''\n",
    "with open('originaltext_cohere_summaries.txt', 'w') as file:\n",
    "    for i in range(len(original_text)):\n",
    "        cohere_summary = co.summarize(text=original_text[i],)\n",
    "        summary = cohere_summary.summary\n",
    "        file.write(summary + '\\n')\n",
    "\n",
    "        time.sleep(12)\n",
    "'''\n",
    "\n",
    "with open('shortenedtext_cohere_summaries.txt', 'w') as file:\n",
    "    for i in range(len(shortened_text)):\n",
    "        cohere_summary = co.summarize(text=shortened_text[i],)\n",
    "        summary = cohere_summary.summary\n",
    "        file.write(summary + '\\n')\n",
    "\n",
    "        time.sleep(12) # only 5 calls per minute with free cohere key\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitbits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2393bc5b12ba71b8b3f7080c5886c93ed036478f03f3d3bfe3eaf6a03080c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
